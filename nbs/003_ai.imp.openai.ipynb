{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ai.imp.openai\n",
    "\n",
    "> The openai implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ai.imp.openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from iagent.ai.messages import HistoryMessage\n",
    "from iagent.ai.responses import ChatCompletionResponse\n",
    "from iagent.ai.service import ChatSettings, ChatClientBase\n",
    "import openai\n",
    "\n",
    "class OpenAI(ChatClientBase):\n",
    "    def __init__(self, client: openai.OpenAI, settings: ChatSettings = None):\n",
    "        self.client = client\n",
    "        self.settings = settings\n",
    "\n",
    "    def chat(self, model: str, messages: HistoryMessage, setting: ChatSettings = None) -> ChatCompletionResponse:\n",
    "        if setting is None:\n",
    "            setting = self.settings\n",
    "\n",
    "        messages_dict = messages.to_dict()\n",
    "        if setting is not None:\n",
    "            return self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages_dict,\n",
    "                temperature=setting.temperature,\n",
    "                max_tokens=setting.max_tokens,\n",
    "                top_p=setting.top_p,\n",
    "                frequency_penalty=setting.frequency_penalty,\n",
    "                presence_penalty=setting.presence_penalty,\n",
    "                stop=setting.stop\n",
    "            )\n",
    "        else:   \n",
    "            return self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages_dict\n",
    "            )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is integration test code\n",
    "\n",
    "# from iagent.ai.messages import UserMessage\n",
    "\n",
    "# user = UserMessage(content=\"Write a one-sentence bedtime story about a unicorn.\")\n",
    "# o_client = openai.OpenAI(api_key=\"anything\", base_url=\"http://0.0.0.0:4000\")\n",
    "\n",
    "# client = OpenAI(client=o_client)\n",
    "\n",
    "# history = HistoryMessage([user])\n",
    "# response = client.chat(\n",
    "#     model=\"gemini-2.5-flash\",\n",
    "#     messages=history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
