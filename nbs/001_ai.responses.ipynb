{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ai.messages\n",
    "\n",
    "> Define message types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ai.responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from iagent.ai.messages import AssistantMessage\n",
    "from typing import List, Optional\n",
    "from typing_extensions import Literal\n",
    "from pydantic import BaseModel\n",
    "#\n",
    "# The type definitions are adapted by reference on OPENAI specifications \n",
    "# to avoid huge dependency\n",
    "#\n",
    "\n",
    "\n",
    "class CompletionUsage(BaseModel):\n",
    "    completion_tokens: int\n",
    "    \"\"\"Number of tokens in the generated completion.\"\"\"\n",
    "\n",
    "    prompt_tokens: int\n",
    "    \"\"\"Number of tokens in the prompt.\"\"\"\n",
    "\n",
    "    total_tokens: int\n",
    "    \"\"\"Total number of tokens used in the request (prompt + completion).\"\"\"\n",
    "\n",
    "    model_config = {\n",
    "        \"extra\": \"allow\"\n",
    "    }\n",
    "\n",
    "\n",
    "class Choice(BaseModel):\n",
    "    finish_reason: Literal[\"stop\", \"length\", \"tool_calls\", \"content_filter\", \"function_call\"]\n",
    "    \"\"\"The reason the model stopped generating tokens.\n",
    "\n",
    "    This will be `stop` if the model hit a natural stop point or a provided stop\n",
    "    sequence, `length` if the maximum number of tokens specified in the request was\n",
    "    reached, `content_filter` if content was omitted due to a flag from our content\n",
    "    filters, `tool_calls` if the model called a tool, or `function_call`\n",
    "    (deprecated) if the model called a function.\n",
    "    \"\"\"\n",
    "\n",
    "    index: int\n",
    "    \"\"\"The index of the choice in the list of choices.\"\"\"\n",
    "\n",
    "    message: AssistantMessage\n",
    "    \"\"\"A chat completion message generated by the model.\"\"\"\n",
    "\n",
    "    model_config = {\n",
    "        \"extra\": \"allow\"\n",
    "    }\n",
    "\n",
    "class ChatCompletionResponse(BaseModel):\n",
    "    id: str\n",
    "    \"\"\"A unique identifier for the chat completion.\"\"\"\n",
    "\n",
    "    choices: List[Choice]\n",
    "    \"\"\"A list of chat completion choices.\n",
    "\n",
    "    Can be more than one if `n` is greater than 1.\n",
    "    \"\"\"\n",
    "\n",
    "    created: int\n",
    "    \"\"\"The Unix timestamp (in seconds) of when the chat completion was created.\"\"\"\n",
    "\n",
    "    model: str\n",
    "    \"\"\"The model used for the chat completion.\"\"\"\n",
    "\n",
    "    usage: Optional[CompletionUsage] = None\n",
    "    \"\"\"Usage statistics for the completion request.\"\"\"\n",
    "\n",
    "    model_config = {\n",
    "        \"extra\": \"allow\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iagent.ai.messages import Function, ToolCall, Annotation, AnnotationURLCitation\n",
    "# Basic ChatCompletionResponse with minimal fields\n",
    "basic_response = ChatCompletionResponse(\n",
    "    id=\"chatcmpl-123\",\n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=AssistantMessage(content=\"Hello, how can I help you today?\")\n",
    "        )\n",
    "    ],\n",
    "    created=1677858242,\n",
    "    model=\"gpt-4\"\n",
    ")\n",
    "assert basic_response.id == \"chatcmpl-123\"\n",
    "assert len(basic_response.choices) == 1\n",
    "assert basic_response.choices[0].finish_reason == \"stop\"\n",
    "assert basic_response.choices[0].index == 0\n",
    "assert basic_response.choices[0].message.content == \"Hello, how can I help you today?\"\n",
    "assert basic_response.created == 1677858242\n",
    "assert basic_response.model == \"gpt-4\"\n",
    "assert basic_response.usage is None\n",
    "\n",
    "# ChatCompletionResponse with usage information\n",
    "response_with_usage = ChatCompletionResponse(\n",
    "    id=\"chatcmpl-456\",\n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=AssistantMessage(content=\"The weather in San Francisco is sunny.\")\n",
    "        )\n",
    "    ],\n",
    "    created=1677858300,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    usage=CompletionUsage(\n",
    "        prompt_tokens=10,\n",
    "        completion_tokens=8,\n",
    "        total_tokens=18\n",
    "    )\n",
    ")\n",
    "assert response_with_usage.id == \"chatcmpl-456\"\n",
    "assert response_with_usage.usage.prompt_tokens == 10\n",
    "assert response_with_usage.usage.completion_tokens == 8\n",
    "assert response_with_usage.usage.total_tokens == 18\n",
    "\n",
    "# ChatCompletionResponse with multiple choices\n",
    "multi_choice_response = ChatCompletionResponse(\n",
    "    id=\"chatcmpl-789\",\n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=AssistantMessage(content=\"Option 1: Go to the park.\")\n",
    "        ),\n",
    "        Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=1,\n",
    "            message=AssistantMessage(content=\"Option 2: Stay home and read a book.\")\n",
    "        )\n",
    "    ],\n",
    "    created=1677858400,\n",
    "    model=\"gpt-4\"\n",
    ")\n",
    "assert multi_choice_response.id == \"chatcmpl-789\"\n",
    "assert len(multi_choice_response.choices) == 2\n",
    "assert multi_choice_response.choices[0].index == 0\n",
    "assert multi_choice_response.choices[1].index == 1\n",
    "assert \"Option 1\" in multi_choice_response.choices[0].message.content\n",
    "assert \"Option 2\" in multi_choice_response.choices[1].message.content\n",
    "\n",
    "# ChatCompletionResponse with tool calls\n",
    "tool_call_response = ChatCompletionResponse(\n",
    "    id=\"chatcmpl-tool123\",\n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason=\"tool_calls\",\n",
    "            index=0,\n",
    "            message=AssistantMessage(\n",
    "                content=\"I'll check the weather for you.\",\n",
    "                tool_calls=[\n",
    "                    ToolCall(\n",
    "                        id=\"call_abc123\",\n",
    "                        type=\"function\",\n",
    "                        function=Function(\n",
    "                            name=\"get_weather\",\n",
    "                            arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}'\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    created=1677858500,\n",
    "    model=\"gpt-4\"\n",
    ")\n",
    "assert tool_call_response.id == \"chatcmpl-tool123\"\n",
    "assert tool_call_response.choices[0].finish_reason == \"tool_calls\"\n",
    "assert tool_call_response.choices[0].message.tool_calls[0].function.name == \"get_weather\"\n",
    "assert \"San Francisco\" in tool_call_response.choices[0].message.tool_calls[0].function.arguments\n",
    "\n",
    "# ChatCompletionResponse with content filter\n",
    "content_filter_response = ChatCompletionResponse(\n",
    "    id=\"chatcmpl-filter456\",\n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason=\"content_filter\",\n",
    "            index=0,\n",
    "            message=AssistantMessage(\n",
    "                content=None,\n",
    "                refusal=\"I cannot provide the requested content as it violates content policies.\"\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    created=1677858600,\n",
    "    model=\"gpt-4\"\n",
    ")\n",
    "assert content_filter_response.id == \"chatcmpl-filter456\"\n",
    "assert content_filter_response.choices[0].finish_reason == \"content_filter\"\n",
    "assert content_filter_response.choices[0].message.content is None\n",
    "assert \"violates content policies\" in content_filter_response.choices[0].message.refusal\n",
    "\n",
    "# Test serialization/deserialization\n",
    "import json\n",
    "\n",
    "# Serialize and deserialize a basic response\n",
    "json_str = basic_response.model_dump_json()\n",
    "deserialized_response = ChatCompletionResponse.model_validate_json(json_str)\n",
    "assert deserialized_response.id == basic_response.id\n",
    "assert deserialized_response.model == basic_response.model\n",
    "assert deserialized_response.choices[0].message.content == basic_response.choices[0].message.content\n",
    "\n",
    "# Test with complex response containing all fields\n",
    "complex_response = ChatCompletionResponse(\n",
    "    id=\"chatcmpl-complex789\",\n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=AssistantMessage(\n",
    "                content=\"Here's the information you requested.\",\n",
    "                annotations=[\n",
    "                    Annotation(\n",
    "                        type=\"url_citation\",\n",
    "                        url_citation=AnnotationURLCitation(\n",
    "                            start_index=5,\n",
    "                            end_index=25,\n",
    "                            title=\"Research Paper\",\n",
    "                            url=\"https://example.com/research\"\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    created=1677858700,\n",
    "    model=\"gpt-4\",\n",
    "    usage=CompletionUsage(\n",
    "        prompt_tokens=15,\n",
    "        completion_tokens=10,\n",
    "        total_tokens=25\n",
    "    )\n",
    ")\n",
    "\n",
    "# Serialize and deserialize the complex response\n",
    "complex_json = complex_response.model_dump_json()\n",
    "restored_response = ChatCompletionResponse.model_validate_json(complex_json)\n",
    "\n",
    "# Verify all fields were preserved\n",
    "assert restored_response.id == complex_response.id\n",
    "assert restored_response.model == complex_response.model\n",
    "assert restored_response.choices[0].message.content == complex_response.choices[0].message.content\n",
    "assert restored_response.choices[0].message.annotations[0].url_citation.title == \"Research Paper\"\n",
    "assert restored_response.usage.total_tokens == 25\n",
    "\n",
    "# Test with extra fields (should be allowed due to model_config)\n",
    "extra_fields_json = '''\n",
    "{\n",
    "    \"id\": \"chatcmpl-extra123\",\n",
    "    \"choices\": [\n",
    "        {\n",
    "            \"finish_reason\": \"stop\",\n",
    "            \"index\": 0,\n",
    "            \"message\": {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Hello there!\"\n",
    "            },\n",
    "            \"custom_choice_field\": \"value\"\n",
    "        }\n",
    "    ],\n",
    "    \"created\": 1677858800,\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"custom_response_field\": \"value\"\n",
    "}\n",
    "'''\n",
    "extra_fields_response = ChatCompletionResponse.model_validate_json(extra_fields_json)\n",
    "assert extra_fields_response.id == \"chatcmpl-extra123\"\n",
    "assert extra_fields_response.choices[0].message.content == \"Hello there!\"\n",
    "\n",
    "# Test with different finish_reason values\n",
    "finish_reasons = [\"stop\", \"length\", \"tool_calls\", \"content_filter\", \"function_call\"]\n",
    "for reason in finish_reasons:\n",
    "    response = ChatCompletionResponse(\n",
    "        id=f\"chatcmpl-{reason}\",\n",
    "        choices=[\n",
    "            Choice(\n",
    "                finish_reason=reason,\n",
    "                index=0,\n",
    "                message=AssistantMessage(content=\"Test message\")\n",
    "            )\n",
    "        ],\n",
    "        created=1677858900,\n",
    "        model=\"gpt-4\"\n",
    "    )\n",
    "    assert response.choices[0].finish_reason == reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
