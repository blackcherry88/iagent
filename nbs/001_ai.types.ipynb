{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ai.messages\n",
    "\n",
    "> Define message types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ai.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Union\n",
    "from typing_extensions import Literal, TypeAlias\n",
    "from pydantic import BaseModel\n",
    "#\n",
    "# The type definitions are adapted by reference on OPENAI specifications.\n",
    "# but decide to go with dataclass instead of TypedDict\n",
    "#\n",
    "\n",
    "@dataclass\n",
    "class InputAudio:\n",
    "    data: str\n",
    "    \"\"\"Base64 encoded audio data.\"\"\"\n",
    "\n",
    "    format: Literal[\"wav\", \"mp3\"]\n",
    "    \"\"\"The format of the encoded audio data.\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class PartInputAudio():\n",
    "    input_audio: InputAudio\n",
    "\n",
    "    type: Optional[Literal[\"input_audio\"]] = \"input_audio\"\n",
    "    \"\"\"The type of the content part. Always `input_audio`.\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class ImageURL():\n",
    "    url: str\n",
    "    \"\"\"Either a URL of the image or the base64 encoded image data.\"\"\"\n",
    "\n",
    "    detail: Optional[Literal[\"auto\", \"low\", \"high\"]] = \"auto\"\n",
    "    \"\"\"Specifies the detail level of the image.\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class PartImage():\n",
    "    image_url: ImageURL\n",
    "\n",
    "    type: Optional[Literal[\"image_url\"]] = \"image_url\"\n",
    "    \"\"\"The type of the content part.\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class PartText():\n",
    "    text: str\n",
    "    \"\"\"The text content.\"\"\"\n",
    "\n",
    "    type: Optional[Literal[\"text\"]] = \"text\"\n",
    "    \"\"\"The type of the content part.\"\"\"\n",
    "\n",
    "\n",
    "ContentPart: TypeAlias = Union[\n",
    "    PartText,\n",
    "    PartImage,\n",
    "    PartInputAudio,\n",
    "]\n",
    "\n",
    "\n",
    "class UserMessage(BaseModel):\n",
    "    content: Union[str, List[ContentPart]]\n",
    "    \"\"\"The contents of the user message.\"\"\"\n",
    "\n",
    "    role: Literal[\"user\"] = \"user\"\n",
    "    \"\"\"The role of the messages author, in this case `user`.\"\"\"\n",
    "\n",
    "    name: Optional[str] = None\n",
    "    \"\"\"An optional name for the participant.\n",
    "\n",
    "    Provides the model information to differentiate between participants of the same\n",
    "    role.\n",
    "    \"\"\"\n",
    "\n",
    "    def addPart(self, part: ContentPart):\n",
    "        \"\"\"\n",
    "        Add a ContentPart to the message content. If content is a string, it will be converted to a list.\n",
    "        \"\"\"\n",
    "        if isinstance(self.content, str):\n",
    "            self.content = [PartText(text=self.content)]\n",
    "        if not isinstance(self.content, list):\n",
    "            self.content = []\n",
    "        self.content.append(part)    \n",
    "\n",
    "\n",
    "class CompletionUsage(BaseModel):\n",
    "    completion_tokens: int\n",
    "    \"\"\"Number of tokens in the generated completion.\"\"\"\n",
    "\n",
    "    prompt_tokens: int\n",
    "    \"\"\"Number of tokens in the prompt.\"\"\"\n",
    "\n",
    "    total_tokens: int\n",
    "    \"\"\"Total number of tokens used in the request (prompt + completion).\"\"\"\n",
    "\n",
    "    model_config = {\n",
    "        \"extra\": \"allow\"\n",
    "    }\n",
    "\n",
    "\n",
    "class AnnotationURLCitation(BaseModel):\n",
    "    end_index: int\n",
    "    \"\"\"The index of the last character of the URL citation in the message.\"\"\"\n",
    "\n",
    "    start_index: int\n",
    "    \"\"\"The index of the first character of the URL citation in the message.\"\"\"\n",
    "\n",
    "    title: str\n",
    "    \"\"\"The title of the web resource.\"\"\"\n",
    "\n",
    "    url: str\n",
    "    \"\"\"The URL of the web resource.\"\"\"\n",
    "\n",
    "\n",
    "class Annotation(BaseModel):\n",
    "    type: Literal[\"url_citation\"]\n",
    "    \"\"\"The type of the URL citation. Always `url_citation`.\"\"\"\n",
    "\n",
    "    url_citation: AnnotationURLCitation\n",
    "    \"\"\"A URL citation when using web search.\"\"\"\n",
    "\n",
    "\n",
    "class AssistantAudio(BaseModel):\n",
    "    id: str\n",
    "    \"\"\"Unique identifier for this audio response.\"\"\"\n",
    "\n",
    "    data: str\n",
    "    \"\"\"\n",
    "    Base64 encoded audio bytes generated by the model, in the format specified in\n",
    "    the request.\n",
    "    \"\"\"\n",
    "\n",
    "    expires_at: int\n",
    "    \"\"\"\n",
    "    The Unix timestamp (in seconds) for when this audio response will no longer be\n",
    "    accessible on the server for use in multi-turn conversations.\n",
    "    \"\"\"\n",
    "\n",
    "    transcript: str\n",
    "    \"\"\"Transcript of the audio generated by the model.\"\"\"\n",
    "\n",
    "\n",
    "class Function(BaseModel):\n",
    "    arguments: str\n",
    "    \"\"\"\n",
    "    The arguments to call the function with, as generated by the model in JSON\n",
    "    format. Note that the model does not always generate valid JSON, and may\n",
    "    hallucinate parameters not defined by your function schema. Validate the\n",
    "    arguments in your code before calling your function.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    \"\"\"The name of the function to call.\"\"\"\n",
    "\n",
    "\n",
    "class ToolCallMessage(BaseModel):\n",
    "    id: str\n",
    "    \"\"\"The ID of the tool call.\"\"\"\n",
    "\n",
    "    function: Function\n",
    "    \"\"\"The function that the model called.\"\"\"\n",
    "\n",
    "    type: Literal[\"function\"]\n",
    "    \"\"\"The type of the tool. Currently, only `function` is supported.\"\"\"\n",
    "\n",
    "\n",
    "class AssistantMessage(BaseModel):\n",
    "    content: Optional[str] = None\n",
    "    \"\"\"The contents of the message.\"\"\"\n",
    "\n",
    "    refusal: Optional[str] = None\n",
    "    \"\"\"The refusal message generated by the model.\"\"\"\n",
    "\n",
    "    role: Literal[\"assistant\"] = \"assistant\"\n",
    "    \"\"\"The role of the author of this message.\"\"\"\n",
    "\n",
    "    annotations: Optional[List[Annotation]] = None\n",
    "    \"\"\"\n",
    "    Annotations for the message, when applicable, as when using the\n",
    "    \"\"\"\n",
    "\n",
    "    audio: Optional[AssistantAudio] = None\n",
    "    \"\"\"\n",
    "    If the audio output modality is requested, this object contains data about the\n",
    "    audio response from the model.\n",
    "    \"\"\"\n",
    "\n",
    "    tool_calls: Optional[List[ToolCallMessage]] = None\n",
    "    \"\"\"The tool calls generated by the model, such as function calls.\"\"\"\n",
    "\n",
    "    model_config = {\n",
    "        \"extra\": \"allow\"\n",
    "    }\n",
    "\n",
    "class Choice(BaseModel):\n",
    "    finish_reason: Literal[\"stop\", \"length\", \"tool_calls\", \"content_filter\", \"function_call\"]\n",
    "    \"\"\"The reason the model stopped generating tokens.\n",
    "\n",
    "    This will be `stop` if the model hit a natural stop point or a provided stop\n",
    "    sequence, `length` if the maximum number of tokens specified in the request was\n",
    "    reached, `content_filter` if content was omitted due to a flag from our content\n",
    "    filters, `tool_calls` if the model called a tool, or `function_call`\n",
    "    (deprecated) if the model called a function.\n",
    "    \"\"\"\n",
    "\n",
    "    index: int\n",
    "    \"\"\"The index of the choice in the list of choices.\"\"\"\n",
    "\n",
    "    message: AssistantMessage\n",
    "    \"\"\"A chat completion message generated by the model.\"\"\"\n",
    "\n",
    "    model_config = {\n",
    "        \"extra\": \"allow\"\n",
    "    }\n",
    "\n",
    "\n",
    "class ChatCompletionMessage(BaseModel):\n",
    "    id: str\n",
    "    \"\"\"A unique identifier for the chat completion.\"\"\"\n",
    "\n",
    "    choices: List[Choice]\n",
    "    \"\"\"A list of chat completion choices.\n",
    "\n",
    "    Can be more than one if `n` is greater than 1.\n",
    "    \"\"\"\n",
    "\n",
    "    created: int\n",
    "    \"\"\"The Unix timestamp (in seconds) of when the chat completion was created.\"\"\"\n",
    "\n",
    "    model: str\n",
    "    \"\"\"The model used for the chat completion.\"\"\"\n",
    "\n",
    "    usage: Optional[CompletionUsage] = None\n",
    "    \"\"\"Usage statistics for the completion request.\"\"\"\n",
    "\n",
    "    model_config = {\n",
    "        \"extra\": \"allow\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userMessage = UserMessage(content=\"Write a one-sentence bedtime story about a unicorn.\")\n",
    "assert userMessage.role == 'user'\n",
    "assert not userMessage.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = UserMessage(content=[\n",
    "    PartText(text=\"What's in this image?\"),\n",
    "    PartImage(\n",
    "        image_url=ImageURL(\n",
    "            url=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "        )\n",
    "    ),\n",
    "])\n",
    "assert user.content[0].text == \"What's in this image?\"\n",
    "assert user.content[1].type == \"image_url\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.addPart(PartText(\"This is a test\"))\n",
    "assert user.content[2].text == \"This is a test\"\n",
    "assert user.content[2].type == \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
