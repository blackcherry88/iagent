{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b718b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df45c289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b4d41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/taohu/workspace/projects/iagent/scratch/match_server.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcp_server_path = \"./match_server.py\"\n",
    "mcp_server_path = os.path.abspath(mcp_server_path)\n",
    "mcp_server_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a81f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-2.5-flash-preview-04-17\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=None,\n",
    "    max_retries=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524e127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create server parameters for stdio connection\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    # Make sure to update to the full absolute path to your math_server.py file\n",
    "    args=[mcp_server_path],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154439e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Enter stdio_client context'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Enter ClientSession context'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from iagent.core.messages import HumanMessage, ToolMessage\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "async def test_mcp():\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        display(f\"Enter stdio_client context\")\n",
    "        async with ClientSession(read, write) as session:\n",
    "            display(f\"Enter ClientSession context\")\n",
    "            await session.initialize()\n",
    "            tools = await load_mcp_tools(session)\n",
    "            display(f\"Tools:\\n{tools}\")\n",
    "\n",
    "            llm_with_tools = llm.bind_tools(tools)\n",
    "            messages = [HumanMessage(content=\"what's (3 + 5) x 12?\")]\n",
    "            while True:\n",
    "                display(f\"Messages:{messages}\")\n",
    "                ai_msg = await llm_with_tools.ainvoke(messages)\n",
    "                messages.append(ai_msg)\n",
    "                display(f\"Response:{ai_msg}\")\n",
    "                if ai_msg.tool_calls:\n",
    "                    for tool_call in ai_msg.tool_calls:\n",
    "                        display(f\"Tool call: {tool_call}\")\n",
    "                        tool_output = await session.call_tool(tool_call['name'], tool_call['args'])\n",
    "                        display(f\"Tool output: {tool_output}\")\n",
    "                        tool_message = ToolMessage(\n",
    "                            content=tool_output.content,\n",
    "                            tool_call_id=tool_call[\"id\"],\n",
    "                            name=tool_call[\"name\"]\n",
    "                        )\n",
    "                        display(f\"Tool message: {tool_message}\")\n",
    "                        messages.append(tool_message)\n",
    "                else:\n",
    "                    return ai_msg\n",
    "\n",
    "\n",
    "response = await test_mcp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40420f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752cbc04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
