{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df45c289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# os.getenv(\"GOOGLE_PROJECT_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9a81f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-2.5-flash-preview-04-17\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=None,\n",
    "    max_retries=6,\n",
    "    stop=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "524e127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\", additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 17, 'candidates_token_count': 6, 'total_token_count': 180, 'prompt_tokens_details': [{'modality': 1, 'token_count': 17}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 6}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -4.500348726908366, 'model_name': 'gemini-2.5-flash-preview-04-17'}, id='run--818aa6b7-e71e-4be3-8aa1-195c7991d33e-0', usage_metadata={'input_tokens': 17, 'output_tokens': 6, 'total_tokens': 180})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92ffeda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydantic import BaseModel, Field\n",
    "\n",
    "# class GetWeather(BaseModel):\n",
    "#     '''Get the current weather in a given location'''\n",
    "\n",
    "#     location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "# class GetPopulation(BaseModel):\n",
    "#     '''Get the current population in a given location'''\n",
    "\n",
    "#     location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "# llm_with_tools = llm.bind_tools([GetWeather, GetPopulation])\n",
    "# ai_msg = llm_with_tools.invoke(\"Which city is hotter today and which is bigger: LA or NY?\")\n",
    "# ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5154439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is 3 * 12? Also, what is 11 + 49?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatVertexAI] [2.02s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [],\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 80,\n",
      "            \"candidates_token_count\": 10,\n",
      "            \"total_token_count\": 266,\n",
      "            \"prompt_tokens_details\": [\n",
      "              {\n",
      "                \"modality\": 1,\n",
      "                \"token_count\": 80\n",
      "              }\n",
      "            ],\n",
      "            \"candidates_tokens_details\": [\n",
      "              {\n",
      "                \"modality\": 1,\n",
      "                \"token_count\": 10\n",
      "              }\n",
      "            ],\n",
      "            \"cached_content_token_count\": 0,\n",
      "            \"cache_tokens_details\": []\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -3.164294624328613\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"add\",\n",
      "                \"arguments\": \"{\\\"a\\\": 11.0, \\\"b\\\": 49.0}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [],\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 80,\n",
      "                \"candidates_token_count\": 10,\n",
      "                \"total_token_count\": 266,\n",
      "                \"prompt_tokens_details\": [\n",
      "                  {\n",
      "                    \"modality\": 1,\n",
      "                    \"token_count\": 80\n",
      "                  }\n",
      "                ],\n",
      "                \"candidates_tokens_details\": [\n",
      "                  {\n",
      "                    \"modality\": 1,\n",
      "                    \"token_count\": 10\n",
      "                  }\n",
      "                ],\n",
      "                \"cached_content_token_count\": 0,\n",
      "                \"cache_tokens_details\": []\n",
      "              },\n",
      "              \"finish_reason\": \"STOP\",\n",
      "              \"avg_logprobs\": -3.164294624328613,\n",
      "              \"model_name\": \"gemini-2.5-flash-preview-04-17\"\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--63a8ccd4-35a8-414d-9d92-35c9b50e3412-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"multiply\",\n",
      "                \"args\": {\n",
      "                  \"a\": 3.0,\n",
      "                  \"b\": 12.0\n",
      "                },\n",
      "                \"id\": \"001efee6-f772-47f4-9eef-512c55b7dfdf\",\n",
      "                \"type\": \"tool_call\"\n",
      "              },\n",
      "              {\n",
      "                \"name\": \"add\",\n",
      "                \"args\": {\n",
      "                  \"a\": 11.0,\n",
      "                  \"b\": 49.0\n",
      "                },\n",
      "                \"id\": \"ff0bd81e-7f99-4fcb-b8c5-8b17825cd903\",\n",
      "                \"type\": \"tool_call\"\n",
      "              }\n",
      "            ],\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 80,\n",
      "              \"output_tokens\": 10,\n",
      "              \"total_tokens\": 266\n",
      "            },\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[tool:multiply] Entering Tool run with input:\n",
      "\u001b[0m\"{'a': 3.0, 'b': 12.0}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[tool:multiply] [1ms] Exiting Tool run with output:\n",
      "\u001b[0m\"36\"\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[tool:add] Entering Tool run with input:\n",
      "\u001b[0m\"{'a': 11.0, 'b': 49.0}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[tool:add] [1ms] Exiting Tool run with output:\n",
      "\u001b[0m\"60\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"a\": 11.0, \"b\": 49.0}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 80, 'candidates_token_count': 10, 'total_token_count': 266, 'prompt_tokens_details': [{'modality': 1, 'token_count': 80}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 10}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -3.164294624328613, 'model_name': 'gemini-2.5-flash-preview-04-17'}, id='run--63a8ccd4-35a8-414d-9d92-35c9b50e3412-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3.0, 'b': 12.0}, 'id': '001efee6-f772-47f4-9eef-512c55b7dfdf', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11.0, 'b': 49.0}, 'id': 'ff0bd81e-7f99-4fcb-b8c5-8b17825cd903', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 10, 'total_tokens': 266}),\n",
       " ToolMessage(content='36', tool_call_id='001efee6-f772-47f4-9eef-512c55b7dfdf'),\n",
       " ToolMessage(content='60', tool_call_id='ff0bd81e-7f99-4fcb-b8c5-8b17825cd903')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ca64a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is 3 * 12? Also, what is 11 + 49?\\nAI: {'name': 'add', 'arguments': '{\\\"a\\\": 11.0, \\\"b\\\": 49.0}'}\\nTool: 36\\nTool: 60\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatVertexAI] [2.55s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"3 * 12 = 36 and 11 + 49 = 60.\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [],\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 98,\n",
      "            \"candidates_token_count\": 22,\n",
      "            \"total_token_count\": 397,\n",
      "            \"prompt_tokens_details\": [\n",
      "              {\n",
      "                \"modality\": 1,\n",
      "                \"token_count\": 98\n",
      "              }\n",
      "            ],\n",
      "            \"candidates_tokens_details\": [\n",
      "              {\n",
      "                \"modality\": 1,\n",
      "                \"token_count\": 22\n",
      "              }\n",
      "            ],\n",
      "            \"cached_content_token_count\": 0,\n",
      "            \"cache_tokens_details\": []\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -1.9850087599320845\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"3 * 12 = 36 and 11 + 49 = 60.\",\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [],\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 98,\n",
      "                \"candidates_token_count\": 22,\n",
      "                \"total_token_count\": 397,\n",
      "                \"prompt_tokens_details\": [\n",
      "                  {\n",
      "                    \"modality\": 1,\n",
      "                    \"token_count\": 98\n",
      "                  }\n",
      "                ],\n",
      "                \"candidates_tokens_details\": [\n",
      "                  {\n",
      "                    \"modality\": 1,\n",
      "                    \"token_count\": 22\n",
      "                  }\n",
      "                ],\n",
      "                \"cached_content_token_count\": 0,\n",
      "                \"cache_tokens_details\": []\n",
      "              },\n",
      "              \"finish_reason\": \"STOP\",\n",
      "              \"avg_logprobs\": -1.9850087599320845,\n",
      "              \"model_name\": \"gemini-2.5-flash-preview-04-17\"\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--23aa5c11-9814-43ba-957c-5978baef8c4e-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 98,\n",
      "              \"output_tokens\": 22,\n",
      "              \"total_tokens\": 397\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='3 * 12 = 36 and 11 + 49 = 60.', additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 98, 'candidates_token_count': 22, 'total_token_count': 397, 'prompt_tokens_details': [{'modality': 1, 'token_count': 98}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 22}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -1.9850087599320845, 'model_name': 'gemini-2.5-flash-preview-04-17'}, id='run--23aa5c11-9814-43ba-957c-5978baef8c4e-0', usage_metadata={'input_tokens': 98, 'output_tokens': 22, 'total_tokens': 397})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1f902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
