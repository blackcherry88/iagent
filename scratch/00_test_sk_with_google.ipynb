{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e4a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.google.vertex_ai import VertexAIChatCompletion\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ffae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add Google AI Gemini chat service\n",
    "kernel.add_service(\n",
    "    VertexAIChatCompletion(\n",
    "        gemini_model_id=\"gemini-2.5-flash-preview-04-17\",\n",
    "    )\n",
    ")\n",
    "\n",
    "chat_completion = kernel.get_service(type=ChatCompletionClientBase)\n",
    "\n",
    "from semantic_kernel.connectors.ai.google.vertex_ai import VertexAIChatPromptExecutionSettings\n",
    "\n",
    "execution_settings = VertexAIChatPromptExecutionSettings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e9bfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageContent(inner_content=candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"Green leaves in the sun,\\nGentle wind whispers secrets,\\nSummer day arrives.\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  avg_logprobs: -6.4199438656077668\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 4\n",
       "  candidates_token_count: 17\n",
       "  total_token_count: 383\n",
       "  prompt_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 4\n",
       "  }\n",
       "  candidates_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 17\n",
       "  }\n",
       "}\n",
       "model_version: \"gemini-2.5-flash-preview-04-17\"\n",
       "create_time {\n",
       "  seconds: 1745701722\n",
       "  nanos: 352627000\n",
       "}\n",
       "response_id: \"WksNaPPCFZSbm9IPjfOSoA8\"\n",
       ", ai_model_id='gemini-2.5-flash-preview-04-17', metadata={'prompt_feedback': , 'usage': CompletionUsage(prompt_tokens=4, completion_tokens=17), 'index': 0, 'finish_reason': <FinishReason.STOP: 1>, 'safety_ratings': []}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"Green leaves in the sun,\\nGentle wind whispers secrets,\\nSummer day arrives.\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  avg_logprobs: -6.4199438656077668\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 4\n",
       "  candidates_token_count: 17\n",
       "  total_token_count: 383\n",
       "  prompt_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 4\n",
       "  }\n",
       "  candidates_tokens_details {\n",
       "    modality: TEXT\n",
       "    token_count: 17\n",
       "  }\n",
       "}\n",
       "model_version: \"gemini-2.5-flash-preview-04-17\"\n",
       "create_time {\n",
       "  seconds: 1745701722\n",
       "  nanos: 352627000\n",
       "}\n",
       "response_id: \"WksNaPPCFZSbm9IPjfOSoA8\"\n",
       ", ai_model_id=None, metadata={'prompt_feedback': , 'usage': CompletionUsage(prompt_tokens=4, completion_tokens=17), 'index': 0, 'finish_reason': <FinishReason.STOP: 1>, 'safety_ratings': []}, content_type='text', text='Green leaves in the sun,\\nGentle wind whispers secrets,\\nSummer day arrives.', encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>, status=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.contents import ChatMessageContent, TextContent, ImageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Write a haiku?\")\n",
    "\n",
    "response = await chat_completion.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c86b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "349f8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level for  semantic_kernel.kernel to DEBUG.\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s - %(name)s:%(lineno)d - %(levelname)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logging.getLogger(\"kernel\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0981f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "semantic_kernel.connectors.ai.google.vertex_ai.services.vertex_ai_chat_completion.VertexAIChatCompletion"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9c7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class LightsPlugin:\n",
    "    lights = [\n",
    "        {\"id\": 1, \"name\": \"Table Lamp\", \"is_on\": False},\n",
    "        {\"id\": 2, \"name\": \"Porch light\", \"is_on\": False},\n",
    "        {\"id\": 3, \"name\": \"Chandelier\", \"is_on\": True},\n",
    "    ]\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"get_lights\",\n",
    "        description=\"Gets a list of lights and their current state\",\n",
    "    )\n",
    "    def get_state(\n",
    "        self,\n",
    "    ) -> str:\n",
    "        \"\"\"Gets a list of lights and their current state.\"\"\"\n",
    "        return self.lights\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"change_state\",\n",
    "        description=\"Changes the state of the light\",\n",
    "    )\n",
    "    def change_state(\n",
    "        self,\n",
    "        id: int,\n",
    "        is_on: bool,\n",
    "    ) -> str:\n",
    "        \"\"\"Changes the state of the light.\"\"\"\n",
    "        for light in self.lights:\n",
    "            if light[\"id\"] == id:\n",
    "                light[\"is_on\"] = is_on\n",
    "                return light\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca45f10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='Lights', description=None, functions={'change_state': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='change_state', plugin_name='Lights', description='Changes the state of the light', parameters=[KernelParameterMetadata(name='id', description=None, default_value=None, type_='int', is_required=True, type_object=<class 'int'>, schema_data={'type': 'integer'}, include_in_function_choices=True), KernelParameterMetadata(name='is_on', description=None, default_value=None, type_='bool', is_required=True, type_object=<class 'bool'>, schema_data={'type': 'boolean'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x7f5e88eaa2c0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x7f5e88ea8fa0>, method=<bound method LightsPlugin.change_state of <__main__.LightsPlugin object at 0x7f5e4d532500>>, stream_method=None), 'get_lights': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='get_lights', plugin_name='Lights', description='Gets a list of lights and their current state', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x7f5e88eaa8f0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x7f5e4d4e8310>, method=<bound method LightsPlugin.get_state of <__main__.LightsPlugin object at 0x7f5e4d532500>>, stream_method=None)})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the plugin to the kernel\n",
    "plugins = kernel.add_plugin(\n",
    "    LightsPlugin(),\n",
    "    plugin_name=\"Lights\",\n",
    ")\n",
    "plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e6574c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_computed_fields__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_setattr_handlers__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__replace__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_recursion__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " '_parse_or_copy',\n",
       " '_setattr_handler',\n",
       " '_validate_functions',\n",
       " 'add',\n",
       " 'add_dict',\n",
       " 'add_list',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'description',\n",
       " 'dict',\n",
       " 'from_directory',\n",
       " 'from_object',\n",
       " 'from_openapi',\n",
       " 'from_orm',\n",
       " 'from_python_file',\n",
       " 'from_text_search_with_get_search_results',\n",
       " 'from_text_search_with_get_text_search_results',\n",
       " 'from_text_search_with_search',\n",
       " 'functions',\n",
       " 'get',\n",
       " 'get_functions_metadata',\n",
       " 'json',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'name',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'set',\n",
       " 'setdefault',\n",
       " 'update',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(plugins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c323131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Lights\",\\n  \"description\": null,\\n  \"functions\": {\\n    \"change_state\": {\\n      \"metadata\": {\\n        \"name\": \"change_state\",\\n        \"plugin_name\": \"Lights\",\\n        \"description\": \"Changes the state of the light\",\\n        \"parameters\": [\\n          {\\n            \"name\": \"id\",\\n            \"description\": null,\\n            \"default_value\": null,\\n            \"type_\": \"int\",\\n            \"is_required\": true,\\n            \"schema_data\": {\\n              \"type\": \"integer\"\\n            },\\n            \"include_in_function_choices\": true\\n          },\\n          {\\n            \"name\": \"is_on\",\\n            \"description\": null,\\n            \"default_value\": null,\\n            \"type_\": \"bool\",\\n            \"is_required\": true,\\n            \"schema_data\": {\\n              \"type\": \"boolean\"\\n            },\\n            \"include_in_function_choices\": true\\n          }\\n        ],\\n        \"is_prompt\": false,\\n        \"is_asynchronous\": false,\\n        \"return_parameter\": {\\n          \"name\": \"return\",\\n          \"description\": \"\",\\n          \"default_value\": null,\\n          \"type_\": \"str\",\\n          \"is_required\": true,\\n          \"schema_data\": {\\n            \"type\": \"string\"\\n          },\\n          \"include_in_function_choices\": true\\n        },\\n        \"additional_properties\": {}\\n      }\\n    },\\n    \"get_lights\": {\\n      \"metadata\": {\\n        \"name\": \"get_lights\",\\n        \"plugin_name\": \"Lights\",\\n        \"description\": \"Gets a list of lights and their current state\",\\n        \"parameters\": [],\\n        \"is_prompt\": false,\\n        \"is_asynchronous\": false,\\n        \"return_parameter\": {\\n          \"name\": \"return\",\\n          \"description\": \"\",\\n          \"default_value\": null,\\n          \"type_\": \"str\",\\n          \"is_required\": true,\\n          \"schema_data\": {\\n            \"type\": \"string\"\\n          },\\n          \"include_in_function_choices\": true\\n        },\\n        \"additional_properties\": {}\\n      }\\n    }\\n  }\\n}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plugins.model_dump_json(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d060bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_settings = VertexAIChatPromptExecutionSettings()\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e75f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "async def main():\n",
    "    # Create a history of the conversation\n",
    "    history = ChatHistory()\n",
    "\n",
    "    # Initiate a back-and-forth chat\n",
    "    userInput = None\n",
    "    while True:\n",
    "        # Collect user input\n",
    "        userInput = input(\"User > \")\n",
    "\n",
    "        # Terminate the loop if the user says \"exit\"\n",
    "        if userInput == \"exit\":\n",
    "            break\n",
    "\n",
    "        # Add user input to the history\n",
    "        history.add_user_message(userInput)\n",
    "\n",
    "        # Get the response from the AI\n",
    "        result = await chat_completion.get_chat_message_content(\n",
    "            chat_history=history,\n",
    "            settings=execution_settings,\n",
    "            kernel=kernel,\n",
    "        )\n",
    "\n",
    "        # Print the results\n",
    "        print(\"Assistant > \" + str(result))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # Add the message from the agent to the chat history\n",
    "        history.add_message(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "958fe4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > You have 3 lights.\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9847aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc059e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
