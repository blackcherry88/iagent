"""Define message types"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../../../nbs/001_ai.responses.ipynb.

# %% auto 0
__all__ = ["CompletionUsage", "Choice", "ChatCompletionResponse"]

from typing import List, Optional

from pydantic import BaseModel
from typing_extensions import Literal

# %% ../../../nbs/001_ai.responses.ipynb 4
from .messages import AssistantMessage

#
# The type definitions are adapted by reference on OPENAI specifications
# to avoid huge dependency
#


class CompletionUsage(BaseModel):
    completion_tokens: int
    """Number of tokens in the generated completion."""

    prompt_tokens: int
    """Number of tokens in the prompt."""

    total_tokens: int
    """Total number of tokens used in the request (prompt + completion)."""

    model_config = {"extra": "allow"}


class Choice(BaseModel):
    finish_reason: Literal[
        "stop", "length", "tool_calls", "content_filter", "function_call"
    ]
    """The reason the model stopped generating tokens.

    This will be `stop` if the model hit a natural stop point or a provided stop
    sequence, `length` if the maximum number of tokens specified in the request was
    reached, `content_filter` if content was omitted due to a flag from our content
    filters, `tool_calls` if the model called a tool, or `function_call`
    (deprecated) if the model called a function.
    """

    index: int
    """The index of the choice in the list of choices."""

    message: AssistantMessage
    """A chat completion message generated by the model."""

    model_config = {"extra": "allow"}


class ChatCompletionResponse(BaseModel):
    id: str
    """A unique identifier for the chat completion."""

    choices: List[Choice]
    """A list of chat completion choices.

    Can be more than one if `n` is greater than 1.
    """

    created: int
    """The Unix timestamp (in seconds) of when the chat completion was created."""

    model: str
    """The model used for the chat completion."""

    usage: Optional[CompletionUsage] = None
    """Usage statistics for the completion request."""

    model_config = {"extra": "allow"}
